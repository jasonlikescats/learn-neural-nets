{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonlikescats/learn-neural-nets/blob/colab/text-gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "af05478e-92e5-49a0-9e9d-389327f1d4a3",
      "metadata": {
        "id": "af05478e-92e5-49a0-9e9d-389327f1d4a3"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from graphviz import Digraph\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "75d11b33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d11b33",
        "outputId": "41703eb3-e098-4e5c-9e0e-01474a9664a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn', 'abigail', 'emily', 'elizabeth', 'mila', 'ella', 'avery', 'sofia', 'camila', 'aria', 'scarlett']\n"
          ]
        }
      ],
      "source": [
        "# read names.txt\n",
        "with open('names.txt') as f:\n",
        "    names = f.read().splitlines()\n",
        "\n",
        "print(names[:20])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# abstract base\n",
        "class NGramModel(ABC):\n",
        "    delimiter_token = \".\"\n",
        "    vocab = [delimiter_token] + list(string.ascii_lowercase)\n",
        "\n",
        "    @abstractmethod\n",
        "    def train(self, words):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @abstractmethod\n",
        "    def loss(self, words):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _inputs(self, words, pad_count = 1):\n",
        "        for w in words:\n",
        "            encoded = self._encode(w, pad_count)\n",
        "            for ngrams in self._ngrams(encoded):\n",
        "                yield ngrams\n",
        "\n",
        "    def _encode(self, word, pad_count = 1):\n",
        "        # pad the word with `pad_count` start tokens, and a trailing end token\n",
        "        delim_token = self.__class__.delimiter_token\n",
        "        padded_word = delim_token * pad_count + word + delim_token\n",
        "        encoded = [self.vocab.index(c) for c in padded_word]\n",
        "        return encoded\n",
        "\n",
        "    def _ngrams(self, encoded_word):\n",
        "        for i in range(0, len(encoded_word) - self.n + 1):\n",
        "            yield encoded_word[i:i + self.n]\n",
        "\n",
        "    def _decode(self, encoded):\n",
        "        return \"\".join([self.vocab[i] for i in encoded])\n"
      ],
      "metadata": {
        "id": "x2MnEOBCmCQh"
      },
      "id": "x2MnEOBCmCQh",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "8152f10f",
      "metadata": {
        "id": "8152f10f"
      },
      "outputs": [],
      "source": [
        "class NGramCountingModel(NGramModel):\n",
        "    def __init__(self, n):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "        self.encode_pad_count = self.n - 1\n",
        "        self.counts = torch.ones((len(self.vocab),) * n, dtype=torch.int32) # start at ones to apply some smoothing\n",
        "\n",
        "    def train(self, words):\n",
        "        for input_ngrams in self._inputs(words, pad_count = self.encode_pad_count):\n",
        "            self.counts[tuple(input_ngrams)] += 1\n",
        "\n",
        "        self._normalize()\n",
        "\n",
        "    def loss(self, words):\n",
        "        # calculate negative log likelihood loss\n",
        "        log_likelihood = 0.0\n",
        "        n = 0\n",
        "\n",
        "        for w in words:\n",
        "            encoded = self._encode(w, pad_count = self.encode_pad_count)\n",
        "            for ngrams in self._ngrams(encoded):\n",
        "                prob = self.counts[tuple(ngrams)]\n",
        "                logprob = torch.log(prob)\n",
        "                log_likelihood += logprob\n",
        "                n += 1\n",
        "\n",
        "        nll = -log_likelihood\n",
        "        return nll / n\n",
        "\n",
        "    def predict(self):\n",
        "        # start with n-1 start tokens\n",
        "        prefix = [0] * self.encode_pad_count\n",
        "\n",
        "        # generate a word\n",
        "        word = []\n",
        "        while True:\n",
        "            # get the next token\n",
        "            token = torch.multinomial(self.counts[tuple(prefix)], 1).item()\n",
        "            word.append(token)\n",
        "            prefix = prefix[1:] + [token]\n",
        "            if token == 0:\n",
        "                break\n",
        "        return self._decode(word)\n",
        "\n",
        "    def _normalize(self):\n",
        "        self.counts = self.counts / self.counts.sum(dim=-1, keepdim=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramNeuralNetModel(NGramModel):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.W = torch.randn((len(self.vocab), len(self.vocab)), requires_grad=True)\n",
        "\n",
        "    def train(self, words):\n",
        "        for w in words[:1]:\n",
        "            encoded = self._encode(w)\n",
        "            xs = encoded[:-1]\n",
        "            ys = encoded[1:]\n",
        "\n",
        "    def loss(self, words):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def predict(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "model = NGramNeuralNetModel()\n",
        "model.train(names[:20])"
      ],
      "metadata": {
        "id": "R5Vu342DmAW6"
      },
      "id": "R5Vu342DmAW6",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use a subset of the names as the training set\n",
        "holdout = 0.2\n",
        "training_set = names[:int(len(names) * (1.0 - holdout))]\n",
        "testing_set = names[int(len(names) * (1.0 - holdout)):]"
      ],
      "metadata": {
        "id": "piOza1yPGF3a"
      },
      "id": "piOza1yPGF3a",
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "6c88e28d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c88e28d",
        "outputId": "d32b41b8-96db-491c-b064-5e0dbe4eeba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([27, 27])\n",
            "bigram loss (training set): 2.42488956451416\n",
            "bigram loss (testing set): 2.593641757965088\n",
            "torch.Size([27, 27, 27])\n",
            "trigram loss (training set): 2.1762611865997314\n",
            "trigram loss (testing set): 2.4267663955688477\n",
            "torch.Size([27, 27, 27, 27])\n",
            "quadgram loss (training set): 2.062680959701538\n",
            "quadgram loss (testing set): 2.4178237915039062\n"
          ]
        }
      ],
      "source": [
        "bigram = NGramCountingModel(2)\n",
        "bigram.train(training_set)\n",
        "print(f\"bigram loss (training set): {bigram.loss(training_set)}\")\n",
        "print(f\"bigram loss (testing set): {bigram.loss(testing_set)}\")\n",
        "\n",
        "trigram = NGramCountingModel(3)\n",
        "trigram.train(training_set)\n",
        "print(f\"trigram loss (training set): {trigram.loss(training_set)}\")\n",
        "print(f\"trigram loss (testing set): {trigram.loss(testing_set)}\")\n",
        "\n",
        "quadgram = NGramCountingModel(4)\n",
        "quadgram.train(training_set)\n",
        "print(f\"quadgram loss (training set): {quadgram.loss(training_set)}\")\n",
        "print(f\"quadgram loss (testing set): {quadgram.loss(testing_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "8c1755e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1755e0",
        "outputId": "0dd87946-4951-4d1e-9b42-b12dc4ae39db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIGRAM\n",
            "ya.\n",
            "syahle.\n",
            "ahe.\n",
            "dleekahmangonya.\n",
            "tryahe.\n",
            "chen.\n",
            "ena.\n",
            "dlyamiiae.\n",
            "a.\n",
            "keles.\n",
            "\n",
            "TRIGRAM\n",
            "lo.\n",
            "atoy.\n",
            "alityn.\n",
            "pepolannezika.\n",
            "shallami.\n",
            "ton.\n",
            "clen.\n",
            "camarivie.\n",
            "augrten.\n",
            "kirahmolwqei.\n",
            "\n",
            "QUADGRAM\n",
            "iony.\n",
            "rin.\n",
            "chrizdwtyana.\n",
            "bree.\n",
            "anna.\n",
            "skakoth.\n",
            "elayne.\n",
            "iszripawaejtxpoxkelynnlysqfdcnidebwfmbiaaewbtorpaclely.\n",
            "inaxstpsvqccgkmbrexcqfmfdvushlqqaspiaycg.\n",
            "knaj.\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"BIGRAM\")\n",
        "for i in range(10):\n",
        "    print(bigram.predict())\n",
        "\n",
        "print()\n",
        "print(\"TRIGRAM\")\n",
        "for i in range(10):\n",
        "    print(trigram.predict())\n",
        "\n",
        "print()\n",
        "print(\"QUADGRAM\")\n",
        "for i in range(10):\n",
        "    print(quadgram.predict())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}