{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonlikescats/learn-neural-nets/blob/colab/text-gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "af05478e-92e5-49a0-9e9d-389327f1d4a3",
      "metadata": {
        "id": "af05478e-92e5-49a0-9e9d-389327f1d4a3"
      },
      "outputs": [],
      "source": [
        "from graphviz import Digraph\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "75d11b33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d11b33",
        "outputId": "b7964bec-0976-432d-daf3-9e2fa635db61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn', 'abigail', 'emily', 'elizabeth', 'mila', 'ella', 'avery', 'sofia', 'camila', 'aria', 'scarlett']\n"
          ]
        }
      ],
      "source": [
        "# read names.txt\n",
        "with open('names.txt') as f:\n",
        "    names = f.read().splitlines()\n",
        "\n",
        "print(names[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "8152f10f",
      "metadata": {
        "id": "8152f10f"
      },
      "outputs": [],
      "source": [
        "class NGramModel:\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "        self.vocab = [\".\"] + list(string.ascii_lowercase) # '.' is start/end token\n",
        "        self.counts = torch.ones((len(self.vocab),) * n, dtype=torch.int32) # start at ones to apply some smoothing\n",
        "\n",
        "    def train(self, words):\n",
        "        for w in words:\n",
        "            encoded = self._encode(w)\n",
        "            for ngrams in self._ngrams(encoded):\n",
        "                self.counts[tuple(ngrams)] += 1\n",
        "\n",
        "        self._normalize()\n",
        "\n",
        "    def loss(self, words):\n",
        "        # calculate negative log likelihood loss\n",
        "        log_likelihood = 0.0\n",
        "        n = 0\n",
        "\n",
        "        for w in words:\n",
        "            encoded = self._encode(w)\n",
        "            for ngrams in self._ngrams(encoded):\n",
        "                prob = self.counts[tuple(ngrams)]\n",
        "                logprob = torch.log(prob)\n",
        "                log_likelihood += logprob\n",
        "                n += 1\n",
        "\n",
        "        nll = -log_likelihood\n",
        "        return nll / n\n",
        "\n",
        "    def predict(self):\n",
        "        # start with n-1 start tokens\n",
        "        prefix = [0] * (self.n - 1)\n",
        "\n",
        "        # generate a word\n",
        "        word = []\n",
        "        while True:\n",
        "            # get the next token\n",
        "            token = torch.multinomial(self.counts[tuple(prefix)], 1).item()\n",
        "            word.append(token)\n",
        "            prefix = prefix[1:] + [token]\n",
        "            if token == 0:\n",
        "                break\n",
        "        return self._decode(word)\n",
        "\n",
        "    def _encode(self, word):\n",
        "        # pad the word with n-1 start tokens, and a trailing end token\n",
        "        padded_word = \".\" * (self.n - 1) + word + \".\"\n",
        "        encoded = [self.vocab.index(c) for c in padded_word]\n",
        "        return encoded\n",
        "\n",
        "    def _ngrams(self, encoded_word):\n",
        "        for i in range(0, len(encoded_word) - self.n + 1):\n",
        "            yield encoded_word[i:i + self.n]\n",
        "\n",
        "    def _decode(self, encoded):\n",
        "        return \"\".join([self.vocab[i] for i in encoded])\n",
        "\n",
        "    def _normalize(self):\n",
        "        self.counts = self.counts / self.counts.sum(dim=-1, keepdim=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use a subset of the names as the training set\n",
        "holdout = 0.2\n",
        "training_set = names[:int(len(names) * (1.0 - holdout))]\n",
        "testing_set = names[int(len(names) * (1.0 - holdout)):]"
      ],
      "metadata": {
        "id": "piOza1yPGF3a"
      },
      "id": "piOza1yPGF3a",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "6c88e28d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c88e28d",
        "outputId": "da66653e-cb71-4477-f6ec-ea734845b96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram loss (training set): 2.42488956451416\n",
            "bigram loss (testing set): 2.593641757965088\n",
            "trigram loss (training set): 2.17937970161438\n",
            "trigram loss (testing set): 2.344642400741577\n",
            "quadgram loss (training set): 2.0542197227478027\n",
            "quadgram loss (testing set): 2.2288053035736084\n"
          ]
        }
      ],
      "source": [
        "bigram = NGramModel(2)\n",
        "bigram.train(training_set)\n",
        "print(f\"bigram loss (training set): {bigram.loss(training_set)}\")\n",
        "print(f\"bigram loss (testing set): {bigram.loss(testing_set)}\")\n",
        "\n",
        "trigram = NGramModel(3)\n",
        "trigram.train(names)\n",
        "print(f\"trigram loss (training set): {trigram.loss(training_set)}\")\n",
        "print(f\"trigram loss (testing set): {trigram.loss(testing_set)}\")\n",
        "\n",
        "quadgram = NGramModel(4)\n",
        "quadgram.train(names)\n",
        "print(f\"quadgram loss (training set): {quadgram.loss(training_set)}\")\n",
        "print(f\"quadgram loss (testing set): {quadgram.loss(testing_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "8c1755e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1755e0",
        "outputId": "7529eb75-b6f5-4da7-ce6a-1f3135abb77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIGRAM\n",
            "ya.\n",
            "syahle.\n",
            "ahe.\n",
            "dleekahmangonya.\n",
            "tryahe.\n",
            "chen.\n",
            "ena.\n",
            "dlyamiiae.\n",
            "a.\n",
            "keles.\n",
            "\n",
            "TRIGRAM\n",
            "lo.\n",
            "atophasiani.\n",
            "pepolannezelloriahlam.\n",
            "xanna.\n",
            "lun.\n",
            "camarivie.\n",
            "auguth.\n",
            "shirahmolm.\n",
            "ei.\n",
            "tony.\n",
            "\n",
            "QUADGRAM\n",
            "rin.\n",
            "chrishan.\n",
            "ana.\n",
            "baylianna.\n",
            "skaan.\n",
            "hadysyn.\n",
            "nia.\n",
            "rilanaelee.\n",
            "oakley.\n",
            "clara.\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"BIGRAM\")\n",
        "for i in range(10):\n",
        "    print(bigram.predict())\n",
        "\n",
        "print()\n",
        "print(\"TRIGRAM\")\n",
        "for i in range(10):\n",
        "    print(trigram.predict())\n",
        "\n",
        "print()\n",
        "print(\"QUADGRAM\")\n",
        "for i in range(10):\n",
        "    print(quadgram.predict())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HE95s6hy4CnN"
      },
      "id": "HE95s6hy4CnN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}