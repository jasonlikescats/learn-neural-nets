{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonlikescats/learn-neural-nets/blob/colab/text-gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "af05478e-92e5-49a0-9e9d-389327f1d4a3",
      "metadata": {
        "id": "af05478e-92e5-49a0-9e9d-389327f1d4a3"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from graphviz import Digraph\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "75d11b33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d11b33",
        "outputId": "fd0e9b2f-223e-45e6-ddc7-267a2d54d7f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn', 'abigail', 'emily', 'elizabeth', 'mila', 'ella', 'avery', 'sofia', 'camila', 'aria', 'scarlett']\n"
          ]
        }
      ],
      "source": [
        "# read names.txt\n",
        "with open('names.txt') as f:\n",
        "    names = f.read().splitlines()\n",
        "\n",
        "print(names[:20])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# abstract base\n",
        "class NGramModel(ABC):\n",
        "    delimiter_token = \".\"\n",
        "    vocab = [delimiter_token] + list(string.ascii_lowercase)\n",
        "\n",
        "    @abstractmethod\n",
        "    def train(self, words):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @abstractmethod\n",
        "    def loss(self, words):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _inputs(self, words, pad_count = 1):\n",
        "        for w in words:\n",
        "            encoded = self._encode(w, pad_count)\n",
        "            for ngrams in self._ngrams(encoded):\n",
        "                yield ngrams\n",
        "\n",
        "    def _encode(self, word, pad_count = 1):\n",
        "        # pad the word with `pad_count` start tokens, and a trailing end token\n",
        "        delim_token = self.__class__.delimiter_token\n",
        "        padded_word = delim_token * pad_count + word + delim_token\n",
        "        encoded = [self.vocab.index(c) for c in padded_word]\n",
        "        return encoded\n",
        "\n",
        "    def _ngrams(self, encoded_word):\n",
        "        for i in range(0, len(encoded_word) - self.n + 1):\n",
        "            yield encoded_word[i:i + self.n]\n",
        "\n",
        "    def _decode(self, encoded):\n",
        "        return \"\".join([self.vocab[i] for i in encoded])\n"
      ],
      "metadata": {
        "id": "x2MnEOBCmCQh"
      },
      "id": "x2MnEOBCmCQh",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "8152f10f",
      "metadata": {
        "id": "8152f10f"
      },
      "outputs": [],
      "source": [
        "class NGramCountingModel(NGramModel):\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "        self.counts = torch.ones((len(self.vocab),) * n, dtype=torch.int32) # start at ones to apply some smoothing\n",
        "\n",
        "    def train(self, words):\n",
        "        for input_ngrams in self._inputs(words, pad_count = (self.n - 1)):\n",
        "            print(f\"incrementing count for: {tuple(input_ngrams)}\")\n",
        "            self.counts[tuple(input_ngrams)] += 1\n",
        "\n",
        "        print(self.counts.shape)\n",
        "\n",
        "        self._normalize()\n",
        "\n",
        "    def loss(self, words):\n",
        "        # calculate negative log likelihood loss\n",
        "        log_likelihood = 0.0\n",
        "        n = 0\n",
        "\n",
        "        for w in words:\n",
        "            encoded = self._encode(w)\n",
        "            for ngrams in self._ngrams(encoded):\n",
        "                prob = self.counts[tuple(ngrams)]\n",
        "                logprob = torch.log(prob)\n",
        "                log_likelihood += logprob\n",
        "                n += 1\n",
        "\n",
        "        nll = -log_likelihood\n",
        "        return nll / n\n",
        "\n",
        "    def predict(self):\n",
        "        # start with n-1 start tokens\n",
        "        prefix = [0] * (self.n - 1)\n",
        "\n",
        "        # generate a word\n",
        "        word = []\n",
        "        while True:\n",
        "            # get the next token\n",
        "            token = torch.multinomial(self.counts[tuple(prefix)], 1).item()\n",
        "            word.append(token)\n",
        "            prefix = prefix[1:] + [token]\n",
        "            if token == 0:\n",
        "                break\n",
        "        return self._decode(word)\n",
        "\n",
        "    def _normalize(self):\n",
        "        self.counts = self.counts / self.counts.sum(dim=-1, keepdim=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramNeuralNetModel(NGramModel):\n",
        "    def train(self, words):\n",
        "        for w in words[:1]:\n",
        "            encoded = self._encode(w)\n",
        "            xs = encoded[:-1]\n",
        "            ys = encoded[1:]\n",
        "            print(xs)\n",
        "            print(ys)\n",
        "\n",
        "    def loss(self, words):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def predict(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "model = NGramNeuralNetModel()\n",
        "model.train(names[:20])"
      ],
      "metadata": {
        "id": "R5Vu342DmAW6",
        "outputId": "cc26fc02-f606-4b1e-bcc2-707eeaa0a0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "id": "R5Vu342DmAW6",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "NGramModel.__init__() missing 1 required positional argument: 'n'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-f510141f8420>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNGramNeuralNetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: NGramModel.__init__() missing 1 required positional argument: 'n'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use a subset of the names as the training set\n",
        "holdout = 0.2\n",
        "#training_set = names[:int(len(names) * (1.0 - holdout))]\n",
        "training_set = names[:2]\n",
        "testing_set = names[int(len(names) * (1.0 - holdout)):]"
      ],
      "metadata": {
        "id": "piOza1yPGF3a"
      },
      "id": "piOza1yPGF3a",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "6c88e28d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c88e28d",
        "outputId": "2c2aae55-7923-4538-c2a1-2a05e7f2cd32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "incrementing count for: (0, 5)\n",
            "incrementing count for: (5, 13)\n",
            "incrementing count for: (13, 13)\n",
            "incrementing count for: (13, 1)\n",
            "incrementing count for: (1, 0)\n",
            "incrementing count for: (0, 15)\n",
            "incrementing count for: (15, 12)\n",
            "incrementing count for: (12, 9)\n",
            "incrementing count for: (9, 22)\n",
            "incrementing count for: (22, 9)\n",
            "incrementing count for: (9, 1)\n",
            "incrementing count for: (1, 0)\n",
            "torch.Size([27, 27])\n",
            "bigram loss (training set): 2.594874143600464\n",
            "incrementing count for: (0, 0, 5)\n",
            "incrementing count for: (0, 5, 13)\n",
            "incrementing count for: (5, 13, 13)\n",
            "incrementing count for: (13, 13, 1)\n",
            "incrementing count for: (13, 1, 0)\n",
            "incrementing count for: (0, 0, 15)\n",
            "incrementing count for: (0, 15, 12)\n",
            "incrementing count for: (15, 12, 9)\n",
            "incrementing count for: (12, 9, 22)\n",
            "incrementing count for: (9, 22, 9)\n",
            "incrementing count for: (22, 9, 1)\n",
            "incrementing count for: (9, 1, 0)\n",
            "torch.Size([27, 27, 27])\n",
            "trigram loss (training set): 2.639057159423828\n",
            "incrementing count for: (0, 0, 0, 5)\n",
            "incrementing count for: (0, 0, 5, 13)\n",
            "incrementing count for: (0, 5, 13, 13)\n",
            "incrementing count for: (5, 13, 13, 1)\n",
            "incrementing count for: (13, 13, 1, 0)\n",
            "incrementing count for: (0, 0, 0, 15)\n",
            "incrementing count for: (0, 0, 15, 12)\n",
            "incrementing count for: (0, 15, 12, 9)\n",
            "incrementing count for: (15, 12, 9, 22)\n",
            "incrementing count for: (12, 9, 22, 9)\n",
            "incrementing count for: (9, 22, 9, 1)\n",
            "incrementing count for: (22, 9, 1, 0)\n",
            "torch.Size([27, 27, 27, 27])\n",
            "quadgram loss (training set): 2.639057159423828\n"
          ]
        }
      ],
      "source": [
        "bigram = NGramCountingModel(2)\n",
        "bigram.train(training_set)\n",
        "print(f\"bigram loss (training set): {bigram.loss(training_set)}\")\n",
        "#print(f\"bigram loss (testing set): {bigram.loss(testing_set)}\")\n",
        "\n",
        "trigram = NGramCountingModel(3)\n",
        "trigram.train(training_set)\n",
        "print(f\"trigram loss (training set): {trigram.loss(training_set)}\")\n",
        "#print(f\"trigram loss (testing set): {trigram.loss(testing_set)}\")\n",
        "\n",
        "quadgram = NGramCountingModel(4)\n",
        "quadgram.train(training_set)\n",
        "print(f\"quadgram loss (training set): {quadgram.loss(training_set)}\")\n",
        "#print(f\"quadgram loss (testing set): {quadgram.loss(testing_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "8c1755e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1755e0",
        "outputId": "c2819bbf-abc6-4433-a9ea-c89547dfae26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIGRAM\n",
            "yeosyohlvfbgqqdlxgktsmzmgwnyb.\n",
            "tryvwdxchwndenbedlppmjiaeqybkejmszqsqgtoyzjovtkimpupolznnyzujfosjvslrumxtonaclpgcyaqxknvzioiuqrtensqvgsumjqwqeioionyyrmnyctrjzdwtyazxdbpnftaauzyskakoth.\n",
            "eyumwlni.\n",
            "zripawaejtxpoxkelygylxsqfdcnidemwfmbiaaewbtorpaclulyaixbxsmpsvqccgkmbr.\n",
            "bcqfmfdvivhlqqaspiaycg.\n",
            "tnaj.\n",
            "qtjaharpzjdhomfrlwzhwsuecdxlxjaffcgqinsfahigwkychfpnucnlsknkkdimfqcytgmpzildaanaonxdlciav.\n",
            "sshzdgzlgvxvtcgumarxpsbfvvaomwnmandgevfbluadt.\n",
            "rulci.\n",
            "cyjipcsvpwoxarvcbzbe.\n",
            "\n",
            "TRIGRAM\n",
            "fb.\n",
            "dsddtbpfwgjttqp.\n",
            "ckysxxq.\n",
            ".\n",
            "wdsqsbxlkbjiowbkvukyigevzn.\n",
            "yvhhvknikkavva.\n",
            "oxzcffvlklvsgghxnuzbiijhrskwlmqkzsfecfmuilshzwfqnoeqpnqenoponnxvmtlstzzyialmaesaveisztqyntxjmgzyqmefclbldftkfkllejvvqiberuhjrcapghutjhsgtnjoxolblqkrhqhjzhpjd.\n",
            "blaityiegzwpsrfsokqogxdberpjvhzxnurdcpcvpacljmzhkwg.\n",
            "kxxiunnyoldpsafdphkviofdft.\n",
            "dgmvrkrwjbjgiocfuigxypaupvfcoetdgushgxszftbai.\n",
            "\n",
            "QUADGRAM\n",
            "jtiiyhmno.\n",
            "wvzvmtdtntx.\n",
            "eptwjrwaqeulhhdekt.\n",
            "ks.\n",
            "hasmnbqmr.\n",
            "zndcuziajqqckezpewrblmqjofqjshhp.\n",
            "ntweev.\n",
            "cqpvpojtpl.\n",
            "jnzxxdtjhpazvnqfu.\n",
            "wkltucfzi.\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"BIGRAM\")\n",
        "for i in range(10):\n",
        "    print(bigram.predict())\n",
        "\n",
        "print()\n",
        "print(\"TRIGRAM\")\n",
        "for i in range(10):\n",
        "    print(trigram.predict())\n",
        "\n",
        "print()\n",
        "print(\"QUADGRAM\")\n",
        "for i in range(10):\n",
        "    print(quadgram.predict())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HE95s6hy4CnN"
      },
      "id": "HE95s6hy4CnN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}